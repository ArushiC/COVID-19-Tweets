{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Few Business questions that we are trying to answer with this data:\n#### 1. Does most favoritized tweet has any pattern/ trend? <br> 2. Which countries are most people tweeting from? <br> 3. Most favoritized tweets? <br> 4. Most followed people and their description? <br> 5. What is the sentiment in peoples' tweet? <br> 6. Does the sentiment has any correlation with country?","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Import Libraries and Data Load","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport os\nimport string\nimport re\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\npd.set_option('max_colwidth', None)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(os.path.join(dirname, filename))\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploration Data Analysis (EDA)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df.corr())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Detailed Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make a copy of dataframe before making any changes\ntweets = df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert date column to datetime\ntweets['date'] = pd.to_datetime(tweets['date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Take care of nulls in location and description\ntweets.user_location.fillna('Unknown', inplace=True)\ntweets.user_description.fillna('Unknown', inplace=True)\ntweets.source.fillna('Unknown', inplace=True)\ntweets.hashtags.fillna('None', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verify\ntweets.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets.user_location.value_counts().to_frame().style.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Attempt tp clean the location column. There are many other business rules that can be applied to \n# improve the accuracy of different cases. We can also use regular expressions\n\n# If both country and city is mentioned\n\ntweets[\"country\"] = tweets.user_location.apply(lambda x: x.split(\",\")[-1].strip() \\\n                                            if (\",\" in x) else x)\ntweets[\"city\"] = tweets.user_location.apply(lambda x: x.split(\",\")[0].strip() \\\n                                            if (\",\" in x) else x)\n\n# Replacing 2 digit US states with USA except UK\ntweets[\"country\"] = tweets.country.apply(lambda x: 'USA' if len(x.lower().strip())<3 and x!='uk' else x)\n\n# Standarizing case senstive cases\ntweets[\"country\"] = tweets.country.apply(lambda x: 'USA' if x.lower().strip() in \\\n                                      (\"united states, usa, us\") else x)\ntweets[\"country\"] = tweets.country.apply(lambda x: 'India' if x.lower().strip() in \\\n                                      (\"india\") else x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets.country.value_counts().to_frame().style.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## We are able to confirm that US and India are the top countries from where most of the people have tweeted with USA being significantly higher","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets[\"city\"] = tweets.city.apply(lambda x: 'Unknown' if x.lower() in \\\n                                   ['india', 'united states', 'united kingdom', 'uk', 'usa', 'us'] \\\n                                   else x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets.city.value_counts().to_frame().style.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The top 5 cities with highest tweets are seen to be London, New Delhi, New York, Mumbai, Washington.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can see a lot of cases have been taken care of but of course there are many additional business \n# rules that can be applied to improve the accuracy but for now this should be sufficient\ntweets[['user_location','country', 'city']].head(100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# five largest values in column tweets \ntweets.nlargest(5, ['user_favourites']) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check sentiment of tweets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalize the text, convert everything other than a-z, A-Z, 0-9 \n#text = re.sub(r\"[^a-zA-Z0-9]\",\" \",tweets['text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.tokenize import word_tokenize","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"words = word_tokenize(tweets['text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}